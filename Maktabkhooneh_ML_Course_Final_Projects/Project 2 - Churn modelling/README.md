
# ğŸ“‰ Customer Churn Prediction â€“ Final ML Project

This project is a final assignment for a MAKTABKHOONEH machine learning course, focused on **Churn Modelling**. The goal is to predict whether a customer will leave a company (churn) based on various features using machine learning techniques.

## ğŸ¯ Objective

Build a predictive model that:
- Identifies customers likely to leave
- Cleans and prepares the dataset efficiently
- Selects relevant features
- Compares performance across different models

The project emphasizes storytelling and clear data communication, in line with professional **Data Scientist** practices.

---

## ğŸ› ï¸ Project Workflow

### âœ… Step 1: Import Required Libraries
Libraries used include:
- `NumPy`
- `Pandas`
- `Matplotlib` / `Seaborn`

### âœ… Step 2: Data Loading and EDA
- Load the dataset using **Pandas**
- Perform **Exploratory Data Analysis (EDA)**

### âœ… Step 3: Data Cleaning
- Identify and handle **missing values**
- Apply **scaling** and other cleaning operations as necessary

### âœ… Step 4: Visualization & Feature Engineering
- Visualize data using **Seaborn** or **Matplotlib**
- Analyze feature relationships and select important features

### âœ… Step 5: Data Preparation
- Split data into training and testing sets
- Define input features and target variable (churn status)

### âœ… Step 6: Model Training and Comparison

Two models were implemented and compared:

1. **Random Forest Classifier**
2. **Artificial Neural Network (ANN)**

Each model was trained, evaluated, and visualized for performance using metrics like accuracy and loss curves.

### âœ… Step 7: Model Saving and Final Submission
- Save the final model
- Submit via **Jupyter Notebook**
- Upload to Maktabkhooneh platform

---

## ğŸ§  Insights

- Random Forest provided good baseline results with interpretability.
- ANN offered deeper modeling capabilities for complex patterns.
- Comparison between both models allowed evaluation of trade-offs in accuracy and complexity.

---

## ğŸ“Œ Notes

- Data-driven storytelling and model evaluation were essential parts of the project.
- The assignment mimicked real-world data science workflows and decision-making.

